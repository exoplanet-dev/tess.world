{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import h5py\n",
    "import corner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightkurve as lk\n",
    "import matplotlib.pyplot as plt\n",
    "from astroquery.mast import Catalogs, Observations\n",
    "\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "import exoplanet as xo\n",
    "\n",
    "import tess_world\n",
    "tess_world.setup_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toi_num = 514\n",
    "\n",
    "tois = tess_world.get_toi_list()\n",
    "\n",
    "# Select all of the rows in the TOI table that are associated with this target\n",
    "toi = tois[tois.toi == toi_num + 0.01]\n",
    "if not len(toi):\n",
    "    raise RuntimeError(f\"no TOI entry for {toi_num}\")\n",
    "toi = toi.iloc[0]\n",
    "tic = toi.tid\n",
    "tois = tois[tois.tid == tic].sort_values(\"toi\")\n",
    "num_toi = len(tois)\n",
    "\n",
    "# Extract the planet periods\n",
    "period_guess = np.array(tois.pl_orbper, dtype=float)\n",
    "\n",
    "# Convert the phase to TBJD from BJD\n",
    "t0_guess = np.array(tois.pl_tranmid, dtype=float) - 2457000\n",
    "\n",
    "# Convert the depth to parts per thousand from parts per million\n",
    "depth_guess = 1e-3 * np.array(tois.pl_trandep, dtype=float)\n",
    "\n",
    "# Convert the duration to days from hours\n",
    "duration_guess = np.array(tois.pl_trandurh, dtype=float) / 24.0\n",
    "\n",
    "tois[[\"tid\", \"toi\", \"pl_orbper\", \"pl_trandep\", \"pl_trandurh\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary workaround for slow MAST queries with lightkurve\n",
    "observations = Observations.query_criteria(\n",
    "    target_name=f\"{tic}\",\n",
    "    radius=0.0001,\n",
    "    project=[\"TESS\"],\n",
    "    obs_collection=[\"TESS\"],\n",
    "    provenance_name=\"SPOC\",\n",
    "    dataproduct_type=\"timeseries\",\n",
    ")\n",
    "if not len(observations):\n",
    "    raise RuntimeError(\"no 2-minute cadence data\")\n",
    "products = Observations.get_product_list(observations)\n",
    "products = products[products[\"productSubGroupDescription\"] == \"LC\"]\n",
    "files = Observations.download_products(\n",
    "    products, download_dir=tess_world.get_lightkurve_directory()\n",
    ")\n",
    "lcfs = lk.LightCurveCollection(\n",
    "    [lk.open(file).PDCSAP_FLUX for file in files[\"Local Path\"]]\n",
    ")\n",
    "lc = lcfs.stitch().remove_nans()\n",
    "\n",
    "# # To be replaced by:\n",
    "# lcfs = lk.search_lightcurvefile(f\"{tic}\", mission=\"TESS\")\n",
    "# print(f\"Found {len(lcfs)} light curve file(s)\")\n",
    "# lcfs = lcfs.download_all(download_dir=\"./cache/lightkurve\")\n",
    "# lc = lcfs.PDCSAP_FLUX.stitch()\n",
    "# lc = lc.remove_nans().remove_outliers()\n",
    "\n",
    "x = np.ascontiguousarray(lc.time, dtype=np.float64)\n",
    "y = np.ascontiguousarray(1e3 * (lc.flux - 1), dtype=np.float64)\n",
    "yerr = np.ascontiguousarray(1e3 * lc.flux_err, dtype=np.float64)\n",
    "\n",
    "plt.plot(x, y, \"k\", linewidth=0.5)\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"relative flux [ppt]\")\n",
    "_ = plt.title(f\"TOI {toi_num}; TIC {tic}\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with single transits\n",
    "single_transit = period_guess <= 0.0\n",
    "period_guess[single_transit] = x.max() - x.min()\n",
    "period_min = np.maximum(np.abs(t0_guess - x.max()), np.abs(x.min() - t0_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_mask = np.zeros_like(x, dtype=bool)\n",
    "for n in range(num_toi):\n",
    "    delta = max(1.5 * duration_guess[n], 0.1)\n",
    "    if single_transit[n]:\n",
    "        delta = 1.0\n",
    "    x_fold = (x - t0_guess[n] + 0.5 * period_guess[n]) % period_guess[\n",
    "        n\n",
    "    ] - 0.5 * period_guess[n]\n",
    "    transit_mask |= np.abs(x_fold) < delta\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.scatter(x_fold[transit_mask], y[transit_mask], c=x[transit_mask], s=3)\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"relative flux [ppt]\")\n",
    "    plt.colorbar(label=\"time [days]\")\n",
    "    plt.title(f\"TOI {toi_num}.{n + 1:02d}, PDC flux\", fontsize=14)\n",
    "    plt.xlim(-delta, delta)\n",
    "\n",
    "x = np.ascontiguousarray(x[transit_mask])\n",
    "y = np.ascontiguousarray(y[transit_mask])\n",
    "yerr = np.ascontiguousarray(yerr[transit_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(mask=None):\n",
    "    if mask is None:\n",
    "        mask = np.ones_like(x, dtype=bool)\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Stellar parameters\n",
    "        mean = pm.Normal(\"mean\", mu=0.0, sigma=10.0)\n",
    "        u = xo.distributions.QuadLimbDark(\"u\")\n",
    "\n",
    "        # Gaussian process noise model\n",
    "        sigma = pm.InverseGamma(\"sigma\", alpha=3.0, beta=2 * np.median(yerr))\n",
    "        log_S_tot = pm.Normal(\n",
    "            \"log_S_tot\",\n",
    "            mu=np.log(np.median((y[mask] - np.median(y[mask])) ** 2)),\n",
    "            sigma=5.0,\n",
    "        )\n",
    "        log_ell = pm.Normal(\"log_ell\", mu=np.log(1.0), sigma=5.0)\n",
    "        Q = 1.0 / 3.0\n",
    "        w0 = 2 * np.pi * tt.exp(-log_ell)\n",
    "        S0 = tt.exp(log_S_tot + log_ell) / (2 * np.pi * Q)\n",
    "        kernel = xo.gp.terms.SHOTerm(S0=S0, w0=w0, Q=Q)\n",
    "\n",
    "        # Dealing with period, treating single transits properly\n",
    "        period_params = []\n",
    "        periods = []\n",
    "        for n in range(num_toi):\n",
    "            if single_transit[n]:\n",
    "                period = pm.Pareto(\n",
    "                    f\"period_{n}\",\n",
    "                    m=period_min[n],\n",
    "                    alpha=2.0 / 3,\n",
    "                    testval=period_guess[n],\n",
    "                )\n",
    "                period_params.append(period)\n",
    "            else:\n",
    "                log_period = pm.Normal(\n",
    "                    f\"log_period_{n}\", mu=np.log(period_guess[n]), sigma=1.0\n",
    "                )\n",
    "                period = pm.Deterministic(f\"period_{n}\", tt.exp(log_period))\n",
    "                period_params.append(log_period)\n",
    "            periods.append(period)\n",
    "        period = pm.Deterministic(\"period\", tt.stack(periods))\n",
    "\n",
    "        # Transit parameters\n",
    "        t0 = pm.Normal(\"t0\", mu=t0_guess, sigma=1.0, shape=num_toi)\n",
    "        log_dur = pm.Normal(\n",
    "            \"log_duration\", mu=np.log(duration_guess), sigma=5.0, shape=num_toi\n",
    "        )\n",
    "        b = xo.distributions.UnitUniform(\"b\", shape=num_toi)\n",
    "        log_depth = pm.Normal(\n",
    "            \"log_depth\", mu=np.log(depth_guess), sigma=5.0, shape=num_toi\n",
    "        )\n",
    "        depth = pm.Deterministic(\"transit_depth\", tt.exp(log_depth))\n",
    "        dur = pm.Deterministic(\"transit_duration\", tt.exp(log_dur))\n",
    "\n",
    "        # Compute the radius ratio from the transit depth, impact parameter, and\n",
    "        # limb darkening parameters making the small-planet assumption\n",
    "        u1 = u[0]\n",
    "        u2 = u[1]\n",
    "        mu = tt.sqrt(1 - b ** 2)\n",
    "        ror = pm.Deterministic(\n",
    "            \"ror\",\n",
    "            tt.sqrt(\n",
    "                1e-3\n",
    "                * depth\n",
    "                * (1 - u1 / 3 - u2 / 6)\n",
    "                / (1 - u1 * (1 - mu) - u2 * (1 - mu) ** 2)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Set up the orbit\n",
    "        orbit = xo.orbits.KeplerianOrbit(period=period, duration=dur, t0=t0, b=b)\n",
    "\n",
    "        # Geometric probability\n",
    "        pm.Potential(\"geom\", tt.log(orbit.dcosidb))\n",
    "\n",
    "        # We're going to track the implied density for reasons that will become clear later\n",
    "        pm.Deterministic(\"rho_circ\", orbit.rho_star)\n",
    "\n",
    "        # Set up the mean transit model\n",
    "        star = xo.LimbDarkLightCurve(u)\n",
    "\n",
    "        lc_model = tess_world.LightCurveModels(mean, star, orbit, ror)\n",
    "\n",
    "        # Finally the GP observation model\n",
    "        gp = xo.gp.GP(kernel, x[mask], yerr[mask] ** 2 + sigma ** 2, mean=lc_model)\n",
    "        gp.marginal(\"obs\", observed=y[mask])\n",
    "\n",
    "        # Double check that everything looks good - we shouldn't see any NaNs!\n",
    "        print(model.check_test_point())\n",
    "\n",
    "        # Optimize the model\n",
    "        map_soln = model.test_point\n",
    "        map_soln = xo.optimize(map_soln, [sigma])\n",
    "        map_soln = xo.optimize(map_soln, [mean, log_depth, b, log_dur])\n",
    "        map_soln = xo.optimize(map_soln, [sigma, log_S_tot, log_ell])\n",
    "        map_soln = xo.optimize(map_soln, [mean, u])\n",
    "        map_soln = xo.optimize(map_soln, period_params)\n",
    "        map_soln = xo.optimize(map_soln)\n",
    "\n",
    "        # Save some of the key parameters\n",
    "        model.map_soln = map_soln\n",
    "        model.lc_model = lc_model\n",
    "        model.gp = gp\n",
    "        model.mask = mask\n",
    "        model.x = x[mask]\n",
    "        model.y = y[mask]\n",
    "        model.yerr = yerr[mask]\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_with_sigma_clipping(sigma=5.0, maxiter=10):\n",
    "    ntot = len(x)\n",
    "    mask = np.ones_like(x, dtype=bool)\n",
    "    pred = np.zeros_like(y)\n",
    "    for i in range(maxiter):\n",
    "        print(f\"Sigma clipping round {i + 1}\")\n",
    "\n",
    "        with build_model(mask) as model:\n",
    "            pred[mask] = xo.eval_in_model(\n",
    "                model.gp.predict() + model.lc_model(x[mask]), model.map_soln\n",
    "            )\n",
    "            if np.any(~mask):\n",
    "                pred[~mask] = xo.eval_in_model(\n",
    "                    model.gp.predict(x[~mask]) + model.lc_model(x[~mask]),\n",
    "                    model.map_soln,\n",
    "                )\n",
    "\n",
    "        resid = y - pred\n",
    "        rms = np.sqrt(np.median(resid ** 2))\n",
    "        mask = np.abs(resid) < sigma * rms\n",
    "\n",
    "        print(\n",
    "            f\"... clipping {(~mask).sum()} of {len(x)} ({100 * (~mask).sum() / len(x):.1f}%)\"\n",
    "        )\n",
    "\n",
    "        if ntot == mask.sum():\n",
    "            break\n",
    "        ntot = mask.sum()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model_with_sigma_clipping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    gp_pred, lc_pred = xo.eval_in_model(\n",
    "        [model.gp.predict(), model.lc_model.light_curves(model.x)], model.map_soln\n",
    "    )\n",
    "\n",
    "transit_mask = np.zeros_like(x, dtype=bool)\n",
    "for n in range(num_toi):\n",
    "    t0 = model.map_soln[\"t0\"][n]\n",
    "    period = model.map_soln[\"period\"][n]\n",
    "    x_fold = (model.x - t0 + 0.5 * period) % period - 0.5 * period\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.scatter(x_fold, model.y - gp_pred - model.map_soln[\"mean\"], c=model.x, s=3)\n",
    "\n",
    "    inds = np.argsort(x_fold)\n",
    "    plt.plot(x_fold[inds], lc_pred[inds, n], \"k\")\n",
    "\n",
    "    plt.xlabel(\"time since transit [days]\")\n",
    "    plt.ylabel(\"de-trended flux [ppt]\")\n",
    "    plt.colorbar(label=\"time [days]\")\n",
    "    plt.title(f\"TOI {toi_num}.{n + 1:02d}, map model\", fontsize=14)\n",
    "    delta = max(1.5 * duration_guess[n], 0.1)\n",
    "    if single_transit[n]:\n",
    "        delta = 1.0\n",
    "    plt.xlim(-delta, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(toi_num)\n",
    "with model:\n",
    "    trace = pm.sample(\n",
    "        tune=2000,\n",
    "        draws=2000,\n",
    "        start=model.map_soln,\n",
    "        chains=2,\n",
    "        step=xo.get_dense_nuts_step(target_accept=0.9),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = pathlib.Path(os.environ.get(\"OUTPUT_DIRECTORY\", \".\"))\n",
    "\n",
    "# Save the model\n",
    "with open(output_directory / \"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f, -1)\n",
    "\n",
    "# Save the MAP solution\n",
    "with open(output_directory / \"map_soln.json\", \"w\") as f:\n",
    "    json.dump(model.map_soln, f, indent=2, cls=tess_world.NumpyEncoder)\n",
    "\n",
    "# Save the summary statistics\n",
    "summary = pm.summary(trace, round_to=\"none\")\n",
    "summary.to_csv(output_directory / \"summary.csv\")\n",
    "\n",
    "# Save the trace\n",
    "df = pm.trace_to_dataframe(trace, include_transformed=True)\n",
    "stats = pd.DataFrame(\n",
    "    dict((name, trace.get_sampler_stats(name)) for name in trace.stat_names)\n",
    ")\n",
    "with h5py.File(output_directory / \"trace.h5\", \"w\") as f:\n",
    "    f.create_dataset(\"trace\", data=df.to_records(index=False))\n",
    "    f.create_dataset(\"stats\", data=stats.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_period = np.median(trace[\"period\"], axis=0)\n",
    "samples = np.array(trace[\"period\"])\n",
    "samples[:, ~single_transit] = (\n",
    "    24 * 60 * (samples[:, ~single_transit] - median_period[None, ~single_transit])\n",
    ")\n",
    "samples[:, single_transit] = np.log10(samples[:, single_transit])\n",
    "labels = [\n",
    "    f\"$\\log_{{10}} P_{n + 1} / \\mathrm{{day}}$\"\n",
    "    if single_transit[n]\n",
    "    else f\"$\\Delta P_{n + 1}$ [min]\"\n",
    "    for n in range(num_toi)\n",
    "]\n",
    "\n",
    "fig = corner.corner(samples, labels=labels)\n",
    "for n, ax in enumerate(np.diag(np.array(fig.axes).reshape(num_toi, num_toi))):\n",
    "    if single_transit[n]:\n",
    "        continue\n",
    "    ax.set_title(f\"$P_\\mathrm{{ref}} = {median_period[n]:.6f}$\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.concatenate(\n",
    "    (trace[\"ror\"], trace[\"b\"], trace[\"transit_duration\"] * 24,), axis=1\n",
    ")\n",
    "labels = [f\"$R_{n + 1} / R_S$\" for n in range(num_toi)]\n",
    "labels += [f\"$b_{n + 1}$\" for n in range(num_toi)]\n",
    "labels += [f\"$\\\\tau_{n + 1}$ [hr]\" for n in range(num_toi)]\n",
    "\n",
    "_ = corner.corner(samples, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star = Catalogs.query_object(f\"TIC {tic}\", catalog=\"TIC\", radius=0.001)\n",
    "tic_rho_star = float(star[\"rho\"]), float(star[\"e_rho\"])\n",
    "if np.all(np.isfinite(tic_rho_star)):\n",
    "\n",
    "    print(\"rho_star = {0} Â± {1}\".format(*tic_rho_star))\n",
    "\n",
    "    # Extract the implied density from the fit\n",
    "    rho_circ = np.repeat(trace[\"rho_circ\"], 500, axis=0)\n",
    "    period = np.repeat(trace[\"period\"], 500, axis=0)\n",
    "\n",
    "    # Sample eccentricity and omega uniformly\n",
    "    ecc = np.random.uniform(0, 1, len(rho_circ))\n",
    "    omega = np.random.uniform(-np.pi, np.pi, len(rho_circ))\n",
    "\n",
    "    # Compute the \"g\" parameter from Dawson & Johnson and what true\n",
    "    # density that implies\n",
    "    g = (1 + ecc * np.sin(omega)) / np.sqrt(1 - ecc ** 2)\n",
    "    rho = rho_circ / g[:, None] ** 3\n",
    "\n",
    "    # Re-weight these samples to get weighted posterior samples\n",
    "    log_weights = -0.5 * ((rho - tic_rho_star[0]) / tic_rho_star[1]) ** 2\n",
    "\n",
    "    for n in range(num_toi):\n",
    "        weights = np.exp(log_weights[:, n] - np.max(log_weights[:, n]))\n",
    "        if single_transit[n]:\n",
    "            samples = np.vstack((ecc, omega, np.log10(period[:, n]))).T\n",
    "            labels = [\n",
    "                f\"$e_{n + 1}$\",\n",
    "                f\"$\\omega_{n + 1}$\",\n",
    "                f\"$\\log_{{10}} P_{n + 1} / \\mathrm{{day}}$\",\n",
    "            ]\n",
    "        else:\n",
    "            samples = np.vstack((ecc, omega)).T\n",
    "            labels = [f\"$e_{n + 1}$\", f\"$\\omega_{n + 1}$\"]\n",
    "\n",
    "        fig = corner.corner(\n",
    "            samples, weights=weights, plot_datapoints=False, labels=labels,\n",
    "        )\n",
    "        fig.suptitle(f\"TOI {toi_num}.{n + 1:02d}\")\n",
    "\n",
    "else:\n",
    "    print(\"The TIC has no measured density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
